{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNFfd+rX3HG9PJoDxafKvxu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b01834715daa48df9593a302852eb9c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a0c87f3e4a134aa89b2cabdc49679dbb",
              "IPY_MODEL_f5fa1223c59842b7815a25fcabf13d3d"
            ],
            "layout": "IPY_MODEL_0dc9c86576d24bc291452ff451452565"
          }
        },
        "a0c87f3e4a134aa89b2cabdc49679dbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb71abfbbc9a4e4491fa33300ba75f20",
            "placeholder": "​",
            "style": "IPY_MODEL_8cc9920b6d3e4ae8a59154a511c7810b",
            "value": "0.055 MB of 0.055 MB uploaded\r"
          }
        },
        "f5fa1223c59842b7815a25fcabf13d3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa393f55ebdf4abcbd4bf6b4deb75e43",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_28ca667cbe634529b18401af7408deed",
            "value": 1
          }
        },
        "0dc9c86576d24bc291452ff451452565": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb71abfbbc9a4e4491fa33300ba75f20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cc9920b6d3e4ae8a59154a511c7810b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa393f55ebdf4abcbd4bf6b4deb75e43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28ca667cbe634529b18401af7408deed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e5a003f9e5304cefadea978c88ba685e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d6ed0b27ee5c49f0bb55240ed3e8106e",
              "IPY_MODEL_4d06cc021e7a4ce0a3b1febc97aa8169"
            ],
            "layout": "IPY_MODEL_783e7bca7c1c4993a36b60f782c9e6dd"
          }
        },
        "d6ed0b27ee5c49f0bb55240ed3e8106e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_758ee1fc0b9a4da7bf13b51f4cbdb1d8",
            "placeholder": "​",
            "style": "IPY_MODEL_348f2d1b8ac749c9ab6503ad2c99ee57",
            "value": "0.961 MB of 0.961 MB uploaded\r"
          }
        },
        "4d06cc021e7a4ce0a3b1febc97aa8169": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77e4147dda8d42d7b0147c2cd34dd78e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fa5bcd7457ea4e669fc6add27c66ee10",
            "value": 1
          }
        },
        "783e7bca7c1c4993a36b60f782c9e6dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "758ee1fc0b9a4da7bf13b51f4cbdb1d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "348f2d1b8ac749c9ab6503ad2c99ee57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77e4147dda8d42d7b0147c2cd34dd78e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa5bcd7457ea4e669fc6add27c66ee10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Deji01/LLMs/blob/main/LLM_Experiment_Tracking_with_Weights_%26_Biases.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction"
      ],
      "metadata": {
        "id": "KqKRwF3sTb28"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuNzBimbTPm7",
        "outputId": "28722b8e-c35d-41f1-ab84-a5506130af99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.1/254.1 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade openai==0.27.2 tiktoken wandb -qq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import tiktoken\n",
        "import wandb\n",
        "from pprint import pprint\n",
        "from getpass import getpass\n",
        "from wandb.integration.openai import autolog"
      ],
      "metadata": {
        "id": "FTfN0RdxTgPd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.getenv(\"OPENAI_API_KEY\") is None:\n",
        "  if any(['VSCODE' in x for x in os.environ.keys()]):\n",
        "    print('Please enter password in the VS Code prompt at the top of your VS Code window!')\n",
        "  os.environ[\"OPENAI_API_KEY\"] = getpass(\"Paste your OpenAI key from: https://platform.openai.com/account/api-keys\\n\")\n",
        "  openai.api_key = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
        "\n",
        "assert os.getenv(\"OPENAI_API_KEY\", \"\").startswith(\"sk-\"), \"This doesn't look like a valid OpenAI API key\"\n",
        "print(\"OpenAI API key configured\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYt4-bJhTjPl",
        "outputId": "9948115a-60c5-40de-f9d8-242fe08f3260"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paste your OpenAI key from: https://platform.openai.com/account/api-keys\n",
            "··········\n",
            "OpenAI API key configured\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# start logging to W&B\n",
        "autolog({\"project\":\"llmapps\", \"job_type\": \"introduction\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "zLuKKaBST_5r",
        "outputId": "27d909a7-f044-46c5-b630-2cc522c5a749"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240116_173131-p1ox8nzu</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ayodejiyou/llmapps/runs/p1ox8nzu' target=\"_blank\">worldly-waterfall-1</a></strong> to <a href='https://wandb.ai/ayodejiyou/llmapps' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ayodejiyou/llmapps' target=\"_blank\">https://wandb.ai/ayodejiyou/llmapps</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ayodejiyou/llmapps/runs/p1ox8nzu' target=\"_blank\">https://wandb.ai/ayodejiyou/llmapps/runs/p1ox8nzu</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenization"
      ],
      "metadata": {
        "id": "rJ2-EuNCVKM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoding = tiktoken.encoding_for_model(\"text-davinci-003\")\n",
        "enc = encoding.encode(\"Weights & Biases is awesome!\")\n",
        "print(enc)\n",
        "print(encoding.decode(enc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gKHj8fJUt4A",
        "outputId": "00633f55-b55f-4009-e70e-5e3945da8f7d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1135, 2337, 1222, 8436, 1386, 318, 7427, 0]\n",
            "Weights & Biases is awesome!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token_id in enc:\n",
        "    print(f\"{token_id}\\t{encoding.decode([token_id])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ui3g8-0EVPH3",
        "outputId": "61bb400e-c454-41dc-d6c7-38e6005b0abc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1135\tWe\n",
            "2337\tights\n",
            "1222\t &\n",
            "8436\t Bi\n",
            "1386\tases\n",
            "318\t is\n",
            "7427\t awesome\n",
            "0\t!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sampling"
      ],
      "metadata": {
        "id": "KQ-Mhqy7VbL7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_with_temperature(temp):\n",
        "  \"Generate text with a given temperature, higher temperature means more randomness\"\n",
        "  response = openai.Completion.create(\n",
        "    model=\"davinci-002\",\n",
        "    prompt=\"Say something about Weights & Biases\",\n",
        "    max_tokens=50,\n",
        "    temperature=temp,\n",
        "  )\n",
        "  return response.choices[0].text"
      ],
      "metadata": {
        "id": "7XrR0kGrVWKQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for temp in [0, 0.5, 1]:\n",
        "  pprint(f'TEMP: {temp}, GENERATION: {generate_with_temperature(temp)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doItP-7TVenV",
        "outputId": "a9486cbd-b192-4965-ec0b-2451e05ca9d5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('TEMP: 0, GENERATION: \\n'\n",
            " '\\n'\n",
            " 'We are a team of 30+ people building a platform to help data scientists and '\n",
            " 'machine learning engineers build, share, and deploy their models. We are a '\n",
            " 'remote-first company with team members in 10+ countries. We are backed by Y')\n",
            "('TEMP: 0.5, GENERATION: \\n'\n",
            " '\\n'\n",
            " \"I'm a co-founder of W&B and I'm a big fan of the project. I think it's a \"\n",
            " 'really powerful tool for data scientists and engineers to be able to track '\n",
            " \"their experiments and share them with others. It's also a great\")\n",
            "('TEMP: 1, GENERATION:  here.\\n'\n",
            " '\\n'\n",
            " '— — —\\n'\n",
            " '\\n'\n",
            " 'And thank you to Julie Fisher for editing!')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_with_topp(topp):\n",
        "  \"Generate text with a given top-p, higher top-p means more randomness\"\n",
        "  response = openai.Completion.create(\n",
        "    model=\"davinci-002\",\n",
        "    prompt=\"Say something about Weights & Biases\",\n",
        "    max_tokens=50,\n",
        "    top_p=topp,\n",
        "    )\n",
        "  return response.choices[0].text"
      ],
      "metadata": {
        "id": "w7Cj2NXJVh8H"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for topp in [0.1, 0.5, 1]:\n",
        "  pprint(f'TOP_P: {topp}, GENERATION: {generate_with_topp(topp)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBlHFriCXDMc",
        "outputId": "5fa5c99b-792c-4feb-a5b1-423f346c92d4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('TOP_P: 0.1, GENERATION: \\n'\n",
            " '\\n'\n",
            " 'We are a team of 30+ people building a platform to help data scientists and '\n",
            " 'machine learning engineers build, share, and deploy their models. We are a '\n",
            " 'remote-first company with team members in 10+ countries. We are backed by Y')\n",
            "('TOP_P: 0.5, GENERATION:  here. Say something about Weights & Biases here. '\n",
            " 'Say something about Weights & Biases here. Say something about Weights & '\n",
            " 'Biases here. Say something about Weights & Biases here. Say something about '\n",
            " 'Weights & Biases')\n",
            "('TOP_P: 1, GENERATION: \\n'\n",
            " '\\n'\n",
            " 'Works with all platforms (including your own)\\n'\n",
            " '\\n'\n",
            " 'Discover and demo-tialise deeper AI insights')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chat API"
      ],
      "metadata": {
        "id": "nzImInOgXl_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL = \"gpt-3.5-turbo\"\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Say something about Weights & Biases\"},\n",
        "    ],\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FthkCWedXVTa",
        "outputId": "a74b9788-b189-4280-9ee8-1f21472241da"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject chat.completion id=chatcmpl-8hhkugXoRt9y75QWy4vpJVVVo6y4Z at 0x7aea9d2a8400> JSON: {\n",
              "  \"choices\": [\n",
              "    {\n",
              "      \"finish_reason\": \"stop\",\n",
              "      \"index\": 0,\n",
              "      \"logprobs\": null,\n",
              "      \"message\": {\n",
              "        \"content\": \"Weights & Biases is a powerful tool for machine learning experimentation and collaboration. It provides a platform to track and visualize experiments, making it easier to understand and iterate on models. With features like hyperparameter sweeps and experiment comparison, it helps researchers and data scientists optimize their models and make informed decisions. Additionally, Weights & Biases offers integrations with popular machine learning frameworks, making it seamless to incorporate into existing workflows.\",\n",
              "        \"role\": \"assistant\"\n",
              "      }\n",
              "    }\n",
              "  ],\n",
              "  \"created\": 1705426992,\n",
              "  \"id\": \"chatcmpl-8hhkugXoRt9y75QWy4vpJVVVo6y4Z\",\n",
              "  \"model\": \"gpt-3.5-turbo-0613\",\n",
              "  \"object\": \"chat.completion\",\n",
              "  \"system_fingerprint\": null,\n",
              "  \"usage\": {\n",
              "    \"completion_tokens\": 84,\n",
              "    \"prompt_tokens\": 25,\n",
              "    \"total_tokens\": 109\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYJE0EQHXrcY",
        "outputId": "9d1d75a1-3fbb-4330-de6a-4caa5336532b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Weights & Biases is a powerful tool for machine learning experimentation and '\n",
            " 'collaboration. It provides a platform to track and visualize experiments, '\n",
            " 'making it easier to understand and iterate on models. With features like '\n",
            " 'hyperparameter sweeps and experiment comparison, it helps researchers and '\n",
            " 'data scientists optimize their models and make informed decisions. '\n",
            " 'Additionally, Weights & Biases offers integrations with popular machine '\n",
            " 'learning frameworks, making it seamless to incorporate into existing '\n",
            " 'workflows.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248,
          "referenced_widgets": [
            "b01834715daa48df9593a302852eb9c4",
            "a0c87f3e4a134aa89b2cabdc49679dbb",
            "f5fa1223c59842b7815a25fcabf13d3d",
            "0dc9c86576d24bc291452ff451452565",
            "cb71abfbbc9a4e4491fa33300ba75f20",
            "8cc9920b6d3e4ae8a59154a511c7810b",
            "aa393f55ebdf4abcbd4bf6b4deb75e43",
            "28ca667cbe634529b18401af7408deed"
          ]
        },
        "id": "qX4_TmoxX06g",
        "outputId": "33fe3ae4-fee0-4c91-f97b-7b345c0a17b5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.039 MB of 0.039 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b01834715daa48df9593a302852eb9c4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>usage/completion_tokens</td><td>▅▂▃▅▅▁▅▅▅▅▂▅▅▂█</td></tr><tr><td>usage/elapsed_time</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>usage/prompt_tokens</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁█</td></tr><tr><td>usage/total_tokens</td><td>▄▁▂▄▄▁▄▄▄▄▂▄▄▂█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>usage/completion_tokens</td><td>84</td></tr><tr><td>usage/elapsed_time</td><td>0.0</td></tr><tr><td>usage/prompt_tokens</td><td>25</td></tr><tr><td>usage/total_tokens</td><td>109</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">worldly-waterfall-1</strong> at: <a href='https://wandb.ai/ayodejiyou/llmapps/runs/p1ox8nzu' target=\"_blank\">https://wandb.ai/ayodejiyou/llmapps/runs/p1ox8nzu</a><br/>Synced 5 W&B file(s), 15 media file(s), 15 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240116_173131-p1ox8nzu/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generation"
      ],
      "metadata": {
        "id": "9o90w6T2ZkK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -Uqqq rich openai==0.27.2 tiktoken wandb tenacity"
      ],
      "metadata": {
        "id": "wx6geY3PX5jl"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "import openai\n",
        "import tiktoken\n",
        "\n",
        "from pathlib import Path\n",
        "from pprint import pprint\n",
        "from getpass import getpass\n",
        "\n",
        "from rich.markdown import Markdown\n",
        "import pandas as pd\n",
        "from tenacity import (\n",
        "    retry,\n",
        "    stop_after_attempt,\n",
        "    wait_random_exponential, # for exponential backoff\n",
        ")\n",
        "import wandb\n",
        "from wandb.integration.openai import autolog"
      ],
      "metadata": {
        "id": "cgGz8sWBZoVy"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download files on colab\n",
        "if not Path(\"examples.txt\").exists():\n",
        "    !wget https://raw.githubusercontent.com/wandb/edu/main/llm-apps-course/notebooks/{examples,prompt_template,system_template}.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgPloJdlZznU",
        "outputId": "4686a638-fe2e-433a-e120-b1b93296d52b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-16 17:55:04--  https://raw.githubusercontent.com/wandb/edu/main/llm-apps-course/notebooks/examples.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 40595 (40K) [text/plain]\n",
            "Saving to: ‘examples.txt’\n",
            "\n",
            "\rexamples.txt          0%[                    ]       0  --.-KB/s               \rexamples.txt        100%[===================>]  39.64K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-01-16 17:55:04 (11.7 MB/s) - ‘examples.txt’ saved [40595/40595]\n",
            "\n",
            "--2024-01-16 17:55:04--  https://raw.githubusercontent.com/wandb/edu/main/llm-apps-course/notebooks/prompt_template.txt\n",
            "Reusing existing connection to raw.githubusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1054 (1.0K) [text/plain]\n",
            "Saving to: ‘prompt_template.txt’\n",
            "\n",
            "\rprompt_template.txt   0%[                    ]       0  --.-KB/s               \rprompt_template.txt 100%[===================>]   1.03K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-16 17:55:04 (72.6 MB/s) - ‘prompt_template.txt’ saved [1054/1054]\n",
            "\n",
            "--2024-01-16 17:55:04--  https://raw.githubusercontent.com/wandb/edu/main/llm-apps-course/notebooks/system_template.txt\n",
            "Reusing existing connection to raw.githubusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 469 [text/plain]\n",
            "Saving to: ‘system_template.txt’\n",
            "\n",
            "system_template.txt 100%[===================>]     469  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-16 17:55:04 (39.8 MB/s) - ‘system_template.txt’ saved [469/469]\n",
            "\n",
            "FINISHED --2024-01-16 17:55:04--\n",
            "Total wall clock time: 0.4s\n",
            "Downloaded: 3 files, 41K in 0.003s (12.0 MB/s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# start logging to W&B\n",
        "autolog({\"project\":\"llmapps\", \"job_type\": \"generation\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "IhsQ0MGkaZQ0",
        "outputId": "9733a0e5-785e-4b4b-87ec-04ed106972ee"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mayodejiyou\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240116_175611-pybou6br</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ayodejiyou/llmapps/runs/pybou6br' target=\"_blank\">magic-brook-2</a></strong> to <a href='https://wandb.ai/ayodejiyou/llmapps' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ayodejiyou/llmapps' target=\"_blank\">https://wandb.ai/ayodejiyou/llmapps</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ayodejiyou/llmapps/runs/pybou6br' target=\"_blank\">https://wandb.ai/ayodejiyou/llmapps/runs/pybou6br</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Genrating synthetic support questions"
      ],
      "metadata": {
        "id": "7pL3Mna6a28y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
        "def completion_with_backoff(**kwargs):\n",
        "    return openai.ChatCompletion.create(**kwargs)"
      ],
      "metadata": {
        "id": "6cpP3ZvZapua"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"gpt-3.5-turbo\""
      ],
      "metadata": {
        "id": "AYRtFbNqa8-5"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"You are a helpful assistant.\"\n",
        "user_prompt = \"Generate a support question from a W&B user\"\n",
        "\n",
        "def generate_and_print(system_prompt, user_prompt, n=5):\n",
        "    messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_prompt},\n",
        "        ]\n",
        "    responses = completion_with_backoff(\n",
        "        model=MODEL_NAME,\n",
        "        messages=messages,\n",
        "        n = n,\n",
        "        )\n",
        "    for response in responses.choices:\n",
        "        generation = response.message.content\n",
        "        display(Markdown(generation))\n",
        "\n",
        "generate_and_print(system_prompt, user_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "id": "icgnd2g_bABJ",
        "outputId": "7b4ff5c2-84d4-4f2e-d257-873e52f21579"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\"What steps can I take to troubleshoot why my weights and biases are not updating during training?\"                \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\"What steps can I take to troubleshoot why my weights and biases are not updating during training?\"                \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Why is the weight and balance calculation for my aircraft not producing accurate results?                          \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Why is the weight and balance calculation for my aircraft not producing accurate results?                          \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\"What is the best way to troubleshoot and resolve issues with my Weights & Biases integration in my machine        \n",
              "learning project?\"                                                                                                 \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\"What is the best way to troubleshoot and resolve issues with my Weights &amp; Biases integration in my machine        \n",
              "learning project?\"                                                                                                 \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "I'm sorry, but I can't generate a support question from a W&B user without more context. Could you please provide  \n",
              "more information or give an example?                                                                               \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">I'm sorry, but I can't generate a support question from a W&amp;B user without more context. Could you please provide  \n",
              "more information or give an example?                                                                               \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\"What steps can I take to troubleshoot my W&B integration with my machine learning model?\"                         \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\"What steps can I take to troubleshoot my W&amp;B integration with my machine learning model?\"                         \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fewshot"
      ],
      "metadata": {
        "id": "oN-6MARObP65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test if examples.txt is present, download if not\n",
        "if not Path(\"examples.txt\").exists():\n",
        "    !wget https://raw.githubusercontent.com/wandb/edu/main/llm-apps-course/notebooks/examples.txt"
      ],
      "metadata": {
        "id": "KbkC6dn7bCiK"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "delimiter = \"\\t\" # tab separated queries\n",
        "with open(\"examples.txt\", \"r\") as file:\n",
        "    data = file.read()\n",
        "    real_queries = data.split(delimiter)\n",
        "\n",
        "pprint(f\"We have {len(real_queries)} real queries:\")\n",
        "Markdown(f\"Sample one: \\n\\\"{random.choice(real_queries)}\\\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "3q0VtuJkbSW7",
        "outputId": "6759ec1a-8cc7-4660-befa-fee71ee6abcb"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'We have 228 real queries:'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sample one: \"@wandbot (beta). I'm using a free account. How can I share the my existing personal project with      \n",
              "others?  Your past instruction \"Move your personal project to the team by going to the project's settings page and \n",
              "changing the \"Owner\" to the team you created.\" didn't work. Actually, I could not find the bottom. Could you please\n",
              "show me the way of sharing my existing project with others step by step?\"                                          \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Sample one: \"@wandbot (beta). I'm using a free account. How can I share the my existing personal project with      \n",
              "others?  Your past instruction \"Move your personal project to the team by going to the project's settings page and \n",
              "changing the \"Owner\" to the team you created.\" didn't work. Actually, I could not find the bottom. Could you please\n",
              "show me the way of sharing my existing project with others step by step?\"                                          \n",
              "</pre>\n"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_few_shot_prompt(queries, n=3):\n",
        "    prompt = \"Generate a support question from a W&B user\\n\" +\\\n",
        "        \"Below you will find a few examples of real user queries:\\n\"\n",
        "    for _ in range(n):\n",
        "        prompt += random.choice(queries) + \"\\n\"\n",
        "    prompt += \"Let's start!\"\n",
        "    return prompt\n",
        "\n",
        "generation_prompt = generate_few_shot_prompt(real_queries)\n",
        "Markdown(generation_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "id": "5wmH6d4ObUhx",
        "outputId": "10b9463b-7cd2-44db-957a-47f9ff6886a3"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Generate a support question from a W&B user Below you will find a few examples of real user queries: hi champ, what\n",
              "are the best practices to integrate wandb in a kedro project? I got this warning wandb: WARNING Path  wasn't       \n",
              "writable, using system temp directory. Why is that? Is it because I’m running in a directory I lack write          \n",
              "permissions for? I have a question about exporting CSV files from a web panel. Whenever I do this, I always get two\n",
              "extra columns for MAX and MIN values, even if I only have one data curve. Does anyone know how to solve this issue?\n",
              "Let's start!                                                                                                       \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Generate a support question from a W&amp;B user Below you will find a few examples of real user queries: hi champ, what\n",
              "are the best practices to integrate wandb in a kedro project? I got this warning wandb: WARNING Path  wasn't       \n",
              "writable, using system temp directory. Why is that? Is it because I’m running in a directory I lack write          \n",
              "permissions for? I have a question about exporting CSV files from a web panel. Whenever I do this, I always get two\n",
              "extra columns for MAX and MIN values, even if I only have one data curve. Does anyone know how to solve this issue?\n",
              "Let's start!                                                                                                       \n",
              "</pre>\n"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_and_print(system_prompt, user_prompt=generation_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "79lt5XfEbdhc",
        "outputId": "39cb3e8b-8979-4139-a11b-89bfa0d553e2"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1;33m • \u001b[0mHow can I integrate W&B into a Kedro project?                                                                   \n",
              "\u001b[1;33m • \u001b[0mWhy am I getting a warning about Wandb not being writable and using the system temp directory?                  \n",
              "\u001b[1;33m • \u001b[0mHow can I export CSV files from a web panel without getting extra columns for MAX and MIN values?               \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>How can I integrate W&amp;B into a Kedro project?                                                                   \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Why am I getting a warning about Wandb not being writable and using the system temp directory?                  \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>How can I export CSV files from a web panel without getting extra columns for MAX and MIN values?               \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Sure! Here's a support question generated from a W&B user: \"Hey there! I'm working on a Kedro project and I want to\n",
              "integrate W&B. Can you guide me on the best practices to do that?\"                                                 \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Sure! Here's a support question generated from a W&amp;B user: \"Hey there! I'm working on a Kedro project and I want to\n",
              "integrate W&amp;B. Can you guide me on the best practices to do that?\"                                                 \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Sure! Here's a support question generated from the user query you provided:                                        \n",
              "\n",
              "\"Hi there! I'm working on integrating W&B into my Kedro project. Can you provide some best practices or            \n",
              "recommendations for a smooth integration? Thanks in advance!\"                                                      \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Sure! Here's a support question generated from the user query you provided:                                        \n",
              "\n",
              "\"Hi there! I'm working on integrating W&amp;B into my Kedro project. Can you provide some best practices or            \n",
              "recommendations for a smooth integration? Thanks in advance!\"                                                      \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "How can I integrate W&B into my Kedro project following best practices?                                            \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">How can I integrate W&amp;B into my Kedro project following best practices?                                            \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "How can I integrate Wandb into a Kedro project effectively?                                                        \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">How can I integrate Wandb into a Kedro project effectively?                                                        \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add Context & Response\n",
        "Let's create a function to find all the markdown files in a directory and return it's content and path\n"
      ],
      "metadata": {
        "id": "e0kWV4tOb39q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check if directory exists, if not, create it and download the files, e.g if running in colab\n",
        "if not os.path.exists(\"../docs_sample/\"):\n",
        "  !git clone https://github.com/wandb/edu.git\n",
        "  !cp -r edu/llm-apps-course/docs_sample ../"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvD7648DbpmR",
        "outputId": "70c61d85-7c03-4d54-d721-08885855f5d9"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'edu'...\n",
            "remote: Enumerating objects: 2739, done.\u001b[K\n",
            "remote: Counting objects: 100% (808/808), done.\u001b[K\n",
            "remote: Compressing objects: 100% (252/252), done.\u001b[K\n",
            "remote: Total 2739 (delta 667), reused 578 (delta 554), pack-reused 1931\u001b[K\n",
            "Receiving objects: 100% (2739/2739), 22.79 MiB | 15.25 MiB/s, done.\n",
            "Resolving deltas: 100% (1573/1573), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_md_files(directory):\n",
        "    \"Find all markdown files in a directory and return their content and path\"\n",
        "    md_files = []\n",
        "    for file in Path(directory).rglob(\"*.md\"):\n",
        "        with open(file, 'r', encoding='utf-8') as md_file:\n",
        "            content = md_file.read()\n",
        "        md_files.append((file.relative_to(directory), content))\n",
        "    return md_files\n",
        "\n",
        "documents = find_md_files('../docs_sample/')\n",
        "len(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ziL0N06vb-QU",
        "outputId": "03c042a3-359b-4828-f42d-a3de4e259c0b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.encoding_for_model(MODEL_NAME)\n",
        "tokens_per_document = [len(tokenizer.encode(document)) for _, document in documents]\n",
        "pprint(tokens_per_document)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MGrULUncPZA",
        "outputId": "4de256e7-8d0c-4b1e-ef54-021342f8205b"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4179, 2596, 803, 1644, 365, 956, 2529, 2093, 1206, 2940, 537]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extract a random chunk from a document\n",
        "def extract_random_chunk(document, max_tokens=512):\n",
        "    tokens = tokenizer.encode(document)\n",
        "    if len(tokens) <= max_tokens:\n",
        "        return document\n",
        "    start = random.randint(0, len(tokens) - max_tokens)\n",
        "    end = start + max_tokens\n",
        "    return tokenizer.decode(tokens[start:end])"
      ],
      "metadata": {
        "id": "BztoJ25PcgK2"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_context_prompt(chunk):\n",
        "    prompt = \"Generate a support question from a W&B user\\n\" +\\\n",
        "        \"The question should be answerable by provided fragment of W&B documentation.\\n\" +\\\n",
        "        \"Below you will find a fragment of W&B documentation:\\n\" +\\\n",
        "        chunk + \"\\n\" +\\\n",
        "        \"Let's start!\"\n",
        "    return prompt\n",
        "\n",
        "chunk = extract_random_chunk(documents[0][1])\n",
        "generation_prompt = generate_context_prompt(chunk)"
      ],
      "metadata": {
        "id": "ryKbEgPqct47"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Markdown(generation_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hE1MeQorcybT",
        "outputId": "6e4bab13-da3d-477b-b345-41da17b5836d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Generate a support question from a W&B user The question should be answerable by provided fragment of W&B          \n",
              "documentation. Below you will find a fragment of W&B documentation: ) for a free account                           \n",
              "\n",
              "b) Pip install the \u001b[1;36;40mwandb\u001b[0m library                                                                                   \n",
              "\n",
              "c) To login in your training script, you'll need to be signed in to you account at www.wandb.ai, then \u001b[1myou will find\u001b[0m\n",
              "\u001b[1myour API key on the\u001b[0m \u001b]8;id=275477;https://wandb.ai/authorize\u001b\\\u001b[1;4;34mAuthorize page\u001b[0m\u001b]8;;\u001b\\\u001b[1m.\u001b[0m                                                                                \n",
              "\n",
              "If you are using Weights and Biases for the first time you might want to check out our \u001b]8;id=412011;../../quickstart.md\u001b\\\u001b[1;4;34mquickstart\u001b[0m\u001b]8;;\u001b\\****              \n",
              "\n",
              "\n",
              "<Tabs defaultValue=\"cli\" values={[ {label: 'Command Line', value: 'cli'}, {label: 'Notebook', value: 'notebook'},  \n",
              "]}>                                                                                                                \n",
              "\n",
              "\u001b[48;2;39;40;34m                                                                                                                   \n",
              "\u001b[0m\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpip\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34minstall\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mwandb\u001b[0m\u001b[48;2;39;40;34m                                                                                                \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m                                                                                                                 \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mwandb\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mlogin\u001b[0m\u001b[48;2;39;40;34m                                                                                                      \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m                                                                                                                   \n",
              "\u001b[0m\n",
              "\n",
              "\u001b[48;2;39;40;34m                                                                                                                   \n",
              "\u001b[0m\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;237;0;126;48;2;30;0;16m!\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpip\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34minstall\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mwandb\u001b[0m\u001b[48;2;39;40;34m                                                                                               \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m                                                                                                                 \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34mimport\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mwandb\u001b[0m\u001b[48;2;39;40;34m                                                                                                     \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mwandb\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mlogin\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                                    \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m                                                                                                                   \n",
              "\u001b[0m\n",
              "\n",
              "\n",
              "                                       \u001b[1;4mUsing PyTorch Lightning's \u001b[0m\u001b[1;4;36;40mWandbLogger\u001b[0m                                       \n",
              "\n",
              "PyTorch Lightning has a \u001b]8;id=100321;https://pytorch-lightning.readthedocs.io/en/latest/extensions/generated/pytorch_lightning.loggers.WandbLogger.html?highlight=wandblogger\u001b\\\u001b[1;4;36;40mWandbLogger\u001b[0m\u001b]8;;\u001b\\ class that can be used to seamlessly log metrics, model weights, media and     \n",
              "more. Just instantiate the WandbLogger and pass it to Lightning's \u001b[1;36;40mTrainer\u001b[0m.                                         \n",
              "\n",
              "\u001b[48;2;39;40;34m                                                                                                                   \n",
              "\u001b[0m\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mwandb_logger = WandbLogger()\u001b[0m\u001b[48;2;39;40;34m                                                                                     \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtrainer = Trainer(logger=wandb_logger)\u001b[0m\u001b[48;2;39;40;34m                                                                           \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m                                                                                                                   \n",
              "\u001b[0m\n",
              "                                                 \u001b[1mLogger arguments\u001b[0m                                                  \n",
              "\n",
              "Below are some of the most used parameters in WandbLogger, see the PyTorch Lightning \u001b]8;id=870872;https://pytorch-lightning.readthedocs.io/en/latest/extensions/generated/pytorch_lightning.loggers.WandbLogger.html?highlight=wandblogger\u001b\\\u001b[1;4;36;40mWandbLogger\u001b[0m\u001b]8;;\u001b\\\u001b]8;id=308104;https://pytorch-lightning.readthedocs.io/en/latest/extensions/generated/pytorch_lightning.loggers.WandbLogger.html?highlight=wandblogger\u001b\\\u001b[1;4;34m documentation\u001b[0m\u001b]8;;\u001b\\ for \n",
              "a full list and description                                                                                        \n",
              "\n",
              "                                                                                         \n",
              " \u001b[1m \u001b[0m\u001b[1mParameter\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDescription\u001b[0m\u001b[1m                                                              \u001b[0m\u001b[1m \u001b[0m \n",
              " ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \n",
              "  \u001b[1;36;40mproject\u001b[0m     Define what wandb Project to log to                                        \n",
              "  \u001b[1;36;40mname\u001b[0m        Give a name to your wandb run                                              \n",
              "  \u001b[1;36;40mlog_model\u001b[0m   Log all models if \u001b[1;36;40mlog_model=\"all\"\u001b[0m or at end of training if \u001b[1;36;40mlog_model=True\u001b[0m  \n",
              "  \u001b[1;36;40msave_dir\u001b[0m    Path where data is saved                                                   \n",
              "                                                                                         \n",
              "\n",
              "                                     \u001b[1mLog your LightningModule hyperparameters\u001b[0m                                      \n",
              "\n",
              "\u001b[48;2;39;40;34m                                                                                                                   \n",
              "\u001b[0m\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mclass\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;166;226;46;48;2;39;40;34mLitModule\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mLightningModule\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[48;2;39;40;34m                                                                                \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mdef\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;166;226;46;48;2;39;40;34m__init__\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mself\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m*\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34margs\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                                                    \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mLet\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34ms start!\u001b[0m\u001b[48;2;39;40;34m                                                                                                     \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m                                                                                                                   \n",
              "\u001b[0m"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Generate a support question from a W&amp;B user The question should be answerable by provided fragment of W&amp;B          \n",
              "documentation. Below you will find a fragment of W&amp;B documentation: ) for a free account                           \n",
              "\n",
              "b) Pip install the <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">wandb</span> library                                                                                   \n",
              "\n",
              "c) To login in your training script, you'll need to be signed in to you account at www.wandb.ai, then <span style=\"font-weight: bold\">you will find</span>\n",
              "<span style=\"font-weight: bold\">your API key on the</span> <a href=\"https://wandb.ai/authorize\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold; text-decoration: underline\">Authorize page</span></a><span style=\"font-weight: bold\">.</span>                                                                                \n",
              "\n",
              "If you are using Weights and Biases for the first time you might want to check out our <a href=\"../../quickstart.md\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold; text-decoration: underline\">quickstart</span></a>****              \n",
              "\n",
              "\n",
              "&lt;Tabs defaultValue=\"cli\" values={[ {label: 'Command Line', value: 'cli'}, {label: 'Notebook', value: 'notebook'},  \n",
              "]}&gt;                                                                                                                \n",
              "\n",
              "<span style=\"background-color: #272822\">                                                                                                                   \n",
              " </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">pip install wandb</span><span style=\"background-color: #272822\">                                                                                                 </span>\n",
              "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
              "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">wandb login</span><span style=\"background-color: #272822\">                                                                                                       </span>\n",
              "<span style=\"background-color: #272822\">                                                                                                                   \n",
              "</span>\n",
              "\n",
              "<span style=\"background-color: #272822\">                                                                                                                   \n",
              " </span><span style=\"color: #ed007e; text-decoration-color: #ed007e; background-color: #1e0010\">!</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">pip install wandb</span><span style=\"background-color: #272822\">                                                                                                </span>\n",
              "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
              "<span style=\"background-color: #272822\"> </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">import</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> wandb</span><span style=\"background-color: #272822\">                                                                                                      </span>\n",
              "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">wandb</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">login()</span><span style=\"background-color: #272822\">                                                                                                     </span>\n",
              "<span style=\"background-color: #272822\">                                                                                                                   \n",
              "</span>\n",
              "\n",
              "\n",
              "                                       <span style=\"font-weight: bold; text-decoration: underline\">Using PyTorch Lightning's </span><span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold; text-decoration: underline\">WandbLogger</span>                                       \n",
              "\n",
              "PyTorch Lightning has a <a href=\"https://pytorch-lightning.readthedocs.io/en/latest/extensions/generated/pytorch_lightning.loggers.WandbLogger.html?highlight=wandblogger\" target=\"_blank\"><span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold; text-decoration: underline\">WandbLogger</span></a> class that can be used to seamlessly log metrics, model weights, media and     \n",
              "more. Just instantiate the WandbLogger and pass it to Lightning's <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">Trainer</span>.                                         \n",
              "\n",
              "<span style=\"background-color: #272822\">                                                                                                                   \n",
              " </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">wandb_logger = WandbLogger()</span><span style=\"background-color: #272822\">                                                                                      </span>\n",
              "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">trainer = Trainer(logger=wandb_logger)</span><span style=\"background-color: #272822\">                                                                            </span>\n",
              "<span style=\"background-color: #272822\">                                                                                                                   \n",
              "</span>\n",
              "                                                 <span style=\"font-weight: bold\">Logger arguments</span>                                                  \n",
              "\n",
              "Below are some of the most used parameters in WandbLogger, see the PyTorch Lightning <a href=\"https://pytorch-lightning.readthedocs.io/en/latest/extensions/generated/pytorch_lightning.loggers.WandbLogger.html?highlight=wandblogger\" target=\"_blank\"><span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold; text-decoration: underline\">WandbLogger</span></a><a href=\"https://pytorch-lightning.readthedocs.io/en/latest/extensions/generated/pytorch_lightning.loggers.WandbLogger.html?highlight=wandblogger\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold; text-decoration: underline\"> documentation</span></a> for \n",
              "a full list and description                                                                                        \n",
              "\n",
              "                                                                                         \n",
              " <span style=\"font-weight: bold\"> Parameter </span> <span style=\"font-weight: bold\"> Description                                                               </span> \n",
              " ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \n",
              "  <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">project</span>     Define what wandb Project to log to                                        \n",
              "  <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">name</span>        Give a name to your wandb run                                              \n",
              "  <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">log_model</span>   Log all models if <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">log_model=\"all\"</span> or at end of training if <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">log_model=True</span>  \n",
              "  <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">save_dir</span>    Path where data is saved                                                   \n",
              "                                                                                         \n",
              "\n",
              "                                     <span style=\"font-weight: bold\">Log your LightningModule hyperparameters</span>                                      \n",
              "\n",
              "<span style=\"background-color: #272822\">                                                                                                                   \n",
              " </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">class</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #a6e22e; text-decoration-color: #a6e22e; background-color: #272822\">LitModule</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">(LightningModule):</span><span style=\"background-color: #272822\">                                                                                 </span>\n",
              "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">def</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #a6e22e; text-decoration-color: #a6e22e; background-color: #272822\">__init__</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">(self, </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">*</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">args,</span><span style=\"background-color: #272822\">                                                                                     </span>\n",
              "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">Let</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">'s start!</span><span style=\"background-color: #272822\">                                                                                                      </span>\n",
              "<span style=\"background-color: #272822\">                                                                                                                   \n",
              "</span></pre>\n"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_and_print(system_prompt, generation_prompt, n=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "id": "mf0a4iXoc2Ux",
        "outputId": "6ba73615-d0e2-4aa7-f32a-5c40dc7b1c55"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Support Question: How can I log my LightningModule hyperparameters using the WandbLogger in PyTorch Lightning?     \n",
              "\n",
              "Answer: To log your LightningModule hyperparameters using the WandbLogger in PyTorch Lightning, you can follow the \n",
              "example code below:                                                                                                \n",
              "\n",
              "\u001b[48;2;39;40;34m                                                                                                                   \n",
              "\u001b[0m\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mclass\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;166;226;46;48;2;39;40;34mLitModule\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mLightningModule\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[48;2;39;40;34m                                                                                \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mdef\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;166;226;46;48;2;39;40;34m__init__\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mself\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m*\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34margs\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                                                    \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m                                                                                                                   \n",
              "\u001b[0m\n",
              "For more information and a full list of parameters, you can refer to the PyTorch Lightning \u001b]8;id=120769;https://pytorch-lightning.readthedocs.io/en/latest/extensions/generated/pytorch_lightning.loggers.WandbLogger.html?highlight=wandblogger\u001b\\\u001b[1;4;36;40mWandbLogger\u001b[0m\u001b]8;;\u001b\\\u001b]8;id=323459;https://pytorch-lightning.readthedocs.io/en/latest/extensions/generated/pytorch_lightning.loggers.WandbLogger.html?highlight=wandblogger\u001b\\\u001b[1;4;34m \u001b[0m\u001b]8;;\u001b\\            \n",
              "\u001b]8;id=323459;https://pytorch-lightning.readthedocs.io/en/latest/extensions/generated/pytorch_lightning.loggers.WandbLogger.html?highlight=wandblogger\u001b\\\u001b[1;4;34mdocumentation\u001b[0m\u001b]8;;\u001b\\.                                                                                                     \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Support Question: How can I log my LightningModule hyperparameters using the WandbLogger in PyTorch Lightning?     \n",
              "\n",
              "Answer: To log your LightningModule hyperparameters using the WandbLogger in PyTorch Lightning, you can follow the \n",
              "example code below:                                                                                                \n",
              "\n",
              "<span style=\"background-color: #272822\">                                                                                                                   \n",
              " </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">class</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #a6e22e; text-decoration-color: #a6e22e; background-color: #272822\">LitModule</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">(LightningModule):</span><span style=\"background-color: #272822\">                                                                                 </span>\n",
              "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">def</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #a6e22e; text-decoration-color: #a6e22e; background-color: #272822\">__init__</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">(self, </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">*</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">args,</span><span style=\"background-color: #272822\">                                                                                     </span>\n",
              "<span style=\"background-color: #272822\">                                                                                                                   \n",
              "</span>\n",
              "For more information and a full list of parameters, you can refer to the PyTorch Lightning <a href=\"https://pytorch-lightning.readthedocs.io/en/latest/extensions/generated/pytorch_lightning.loggers.WandbLogger.html?highlight=wandblogger\" target=\"_blank\"><span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold; text-decoration: underline\">WandbLogger</span></a><a href=\"https://pytorch-lightning.readthedocs.io/en/latest/extensions/generated/pytorch_lightning.loggers.WandbLogger.html?highlight=wandblogger\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold; text-decoration: underline\"> </span></a>            \n",
              "<a href=\"https://pytorch-lightning.readthedocs.io/en/latest/extensions/generated/pytorch_lightning.loggers.WandbLogger.html?highlight=wandblogger\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold; text-decoration: underline\">documentation</span></a>.                                                                                                     \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Support Question: How can I log my LightningModule hyperparameters using WandbLogger in PyTorch Lightning?         \n",
              "\n",
              "Answer: You can log your LightningModule hyperparameters using WandbLogger by implementing the \u001b[1;36;40mLog your \u001b[0m           \n",
              "\u001b[1;36;40mLightningModule hyperparameters\u001b[0m code snippet provided in the documentation.                                        \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Support Question: How can I log my LightningModule hyperparameters using WandbLogger in PyTorch Lightning?         \n",
              "\n",
              "Answer: You can log your LightningModule hyperparameters using WandbLogger by implementing the <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">Log your </span>           \n",
              "<span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">LightningModule hyperparameters</span> code snippet provided in the documentation.                                        \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Support Question: How can I log metrics, model weights, media, and more using PyTorch Lightning's \u001b[1;36;40mWandbLogger\u001b[0m?     \n",
              "\n",
              "Answer: You can use PyTorch Lightning's \u001b[1;36;40mWandbLogger\u001b[0m class to seamlessly log metrics, model weights, media, and     \n",
              "more. Here's an example of how to use it:                                                                          \n",
              "\n",
              "\u001b[48;2;39;40;34m                                                                                                                   \n",
              "\u001b[0m\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mwandb_logger = WandbLogger()\u001b[0m\u001b[48;2;39;40;34m                                                                                     \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtrainer = Trainer(logger=wandb_logger)\u001b[0m\u001b[48;2;39;40;34m                                                                           \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m                                                                                                                   \n",
              "\u001b[0m\n",
              "You can also specify parameters like \u001b[1;36;40mproject\u001b[0m, \u001b[1;36;40mname\u001b[0m, \u001b[1;36;40mlog_model\u001b[0m, and \u001b[1;36;40msave_dir\u001b[0m when instantiating the \u001b[1;36;40mWandbLogger\u001b[0m. For\n",
              "a full list and description of available parameters, you can refer to the PyTorch Lightning \u001b]8;id=978789;https://pytorch-lightning.readthedocs.io/en/latest/extensions/generated/pytorch_lightning.loggers.WandbLogger.html?highlight=wandblogger\u001b\\\u001b[1;4;36;40mWandbLogger\u001b[0m\u001b]8;;\u001b\\\u001b]8;id=311013;https://pytorch-lightning.readthedocs.io/en/latest/extensions/generated/pytorch_lightning.loggers.WandbLogger.html?highlight=wandblogger\u001b\\\u001b[1;4;34m \u001b[0m\u001b]8;;\u001b\\           \n",
              "\u001b]8;id=311013;https://pytorch-lightning.readthedocs.io/en/latest/extensions/generated/pytorch_lightning.loggers.WandbLogger.html?highlight=wandblogger\u001b\\\u001b[1;4;34mdocumentation\u001b[0m\u001b]8;;\u001b\\.                                                                                                     \n",
              "\n",
              "Additionally, you can log your LightningModule hyperparameters by defining them in your LightningModule class and  \n",
              "they will be automatically logged.                                                                                 \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Support Question: How can I log metrics, model weights, media, and more using PyTorch Lightning's <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">WandbLogger</span>?     \n",
              "\n",
              "Answer: You can use PyTorch Lightning's <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">WandbLogger</span> class to seamlessly log metrics, model weights, media, and     \n",
              "more. Here's an example of how to use it:                                                                          \n",
              "\n",
              "<span style=\"background-color: #272822\">                                                                                                                   \n",
              " </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">wandb_logger = WandbLogger()</span><span style=\"background-color: #272822\">                                                                                      </span>\n",
              "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">trainer = Trainer(logger=wandb_logger)</span><span style=\"background-color: #272822\">                                                                            </span>\n",
              "<span style=\"background-color: #272822\">                                                                                                                   \n",
              "</span>\n",
              "You can also specify parameters like <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">project</span>, <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">name</span>, <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">log_model</span>, and <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">save_dir</span> when instantiating the <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">WandbLogger</span>. For\n",
              "a full list and description of available parameters, you can refer to the PyTorch Lightning <a href=\"https://pytorch-lightning.readthedocs.io/en/latest/extensions/generated/pytorch_lightning.loggers.WandbLogger.html?highlight=wandblogger\" target=\"_blank\"><span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold; text-decoration: underline\">WandbLogger</span></a><a href=\"https://pytorch-lightning.readthedocs.io/en/latest/extensions/generated/pytorch_lightning.loggers.WandbLogger.html?highlight=wandblogger\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold; text-decoration: underline\"> </span></a>           \n",
              "<a href=\"https://pytorch-lightning.readthedocs.io/en/latest/extensions/generated/pytorch_lightning.loggers.WandbLogger.html?highlight=wandblogger\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold; text-decoration: underline\">documentation</span></a>.                                                                                                     \n",
              "\n",
              "Additionally, you can log your LightningModule hyperparameters by defining them in your LightningModule class and  \n",
              "they will be automatically logged.                                                                                 \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read system_template.txt file into an f-string\n",
        "with open(\"system_template.txt\", \"r\") as file:\n",
        "    system_prompt = file.read()"
      ],
      "metadata": {
        "id": "FtyaWtRadLC4"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Markdown(system_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "id": "PxinbPsydaVH",
        "outputId": "3199efd9-7f88-454d-a7ed-79117089985f"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "You are a creative assistant with the goal to generate a synthetic dataset of Weights & Biases (W&B) user          \n",
              "questions. W&B users are asking these questions to a bot, so they don't know the answer and their questions are    \n",
              "grounded in what they're trying to achieve. We are interested in questions that can be answered by W&B             \n",
              "documentation. But the users don't have access to this documentation, so you need to imagine what they're trying to\n",
              "do and use according language.                                                                                     \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">You are a creative assistant with the goal to generate a synthetic dataset of Weights &amp; Biases (W&amp;B) user          \n",
              "questions. W&amp;B users are asking these questions to a bot, so they don't know the answer and their questions are    \n",
              "grounded in what they're trying to achieve. We are interested in questions that can be answered by W&amp;B             \n",
              "documentation. But the users don't have access to this documentation, so you need to imagine what they're trying to\n",
              "do and use according language.                                                                                     \n",
              "</pre>\n"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read prompt_template.txt file into an f-string\n",
        "with open(\"prompt_template.txt\", \"r\") as file:\n",
        "    prompt_template = file.read()"
      ],
      "metadata": {
        "id": "sWJO-ZlYddGd"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Markdown(prompt_template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "rbeX1v5fdnFo",
        "outputId": "34c1be37-ea88-4134-a208-c6d10925854e"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Here are some examples of real user questions, you will be judged by how well you match this distribution.         \n",
              "\n",
              "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
              "{QUESTIONS}                                                                                                        \n",
              "\n",
              "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
              "In the next step, you will read a fragment of W&B documentation. This will serve as inspiration for synthetic user \n",
              "question and the source of the answer. Here is the document fragment:                                              \n",
              "\n",
              "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
              "{CHUNK}                                                                                                            \n",
              "\n",
              "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
              "You will now generate a user question and corresponding answer based on the above document. First, explain the user\n",
              "context and what problems they might be trying to solve. Second, generate user question. Third, provide the        \n",
              "accurate and concise answer in markdown format to the user question using the documentation. You'll be evaluated   \n",
              "on:                                                                                                                \n",
              "\n",
              "\u001b[1;33m • \u001b[0mhow realistic is that this question will come from a real user one day?                                         \n",
              "\u001b[1;33m • \u001b[0mis this question about W&B?                                                                                     \n",
              "\u001b[1;33m • \u001b[0mcan the question be answered using the W&B document fragment above?                                             \n",
              "\u001b[1;33m • \u001b[0mhow accurate is the answer? Remember that users have different styles and can be imprecise. You are very good at\n",
              "\u001b[1;33m   \u001b[0mimpersonating them! Use the following format: CONTEXT: QUESTION: ANSWER: Let's start!                           \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Here are some examples of real user questions, you will be judged by how well you match this distribution.         \n",
              "\n",
              "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
              "{QUESTIONS}                                                                                                        \n",
              "\n",
              "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
              "In the next step, you will read a fragment of W&amp;B documentation. This will serve as inspiration for synthetic user \n",
              "question and the source of the answer. Here is the document fragment:                                              \n",
              "\n",
              "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
              "{CHUNK}                                                                                                            \n",
              "\n",
              "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
              "You will now generate a user question and corresponding answer based on the above document. First, explain the user\n",
              "context and what problems they might be trying to solve. Second, generate user question. Third, provide the        \n",
              "accurate and concise answer in markdown format to the user question using the documentation. You'll be evaluated   \n",
              "on:                                                                                                                \n",
              "\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>how realistic is that this question will come from a real user one day?                                         \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>is this question about W&amp;B?                                                                                     \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>can the question be answered using the W&amp;B document fragment above?                                             \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>how accurate is the answer? Remember that users have different styles and can be imprecise. You are very good at\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>impersonating them! Use the following format: CONTEXT: QUESTION: ANSWER: Let's start!                           \n",
              "</pre>\n"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_context_prompt(chunk, n_questions=3):\n",
        "    questions = '\\n'.join(random.sample(real_queries, n_questions))\n",
        "    user_prompt = prompt_template.format(QUESTIONS=questions, CHUNK=chunk)\n",
        "    return user_prompt\n",
        "\n",
        "user_prompt = generate_context_prompt(chunk)"
      ],
      "metadata": {
        "id": "n_mAYecmdpd3"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Markdown(user_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WkTQhQFxdy_r",
        "outputId": "2e1f2d4c-76cb-4628-9367-e21d619750e5"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Here are some examples of real user questions, you will be judged by how well you match this distribution.         \n",
              "\n",
              "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
              "is there a W&B integration for AutoKeras? Can you tell me why do sweeps often create the same runs and set same    \n",
              "hyper-parameters? I created the sweep with wandb offline. i have my log from training in a txt file. Can i import  \n",
              "that data to wandb so i can visualize the data? I have accuracy and loss logged every 50 steps on training data,   \n",
              "and every 5000 steps on validation data. How can I plot those two different accuracies and their losses?           \n",
              "\n",
              "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
              "In the next step, you will read a fragment of W&B documentation. This will serve as inspiration for synthetic user \n",
              "question and the source of the answer. Here is the document fragment:                                              \n",
              "\n",
              "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
              ") for a free account                                                                                               \n",
              "\n",
              "b) Pip install the \u001b[1;36;40mwandb\u001b[0m library                                                                                   \n",
              "\n",
              "c) To login in your training script, you'll need to be signed in to you account at www.wandb.ai, then \u001b[1myou will find\u001b[0m\n",
              "\u001b[1myour API key on the\u001b[0m \u001b]8;id=616876;https://wandb.ai/authorize\u001b\\\u001b[1;4;34mAuthorize page\u001b[0m\u001b]8;;\u001b\\\u001b[1m.\u001b[0m                                                                                \n",
              "\n",
              "If you are using Weights and Biases for the first time you might want to check out our \u001b]8;id=108453;../../quickstart.md\u001b\\\u001b[1;4;34mquickstart\u001b[0m\u001b]8;;\u001b\\****              \n",
              "\n",
              "\n",
              "<Tabs defaultValue=\"cli\" values={[ {label: 'Command Line', value: 'cli'}, {label: 'Notebook', value: 'notebook'},  \n",
              "]}>                                                                                                                \n",
              "\n",
              "\u001b[48;2;39;40;34m                                                                                                                   \n",
              "\u001b[0m\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpip\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34minstall\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mwandb\u001b[0m\u001b[48;2;39;40;34m                                                                                                \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m                                                                                                                 \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mwandb\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mlogin\u001b[0m\u001b[48;2;39;40;34m                                                                                                      \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m                                                                                                                   \n",
              "\u001b[0m\n",
              "\n",
              "\u001b[48;2;39;40;34m                                                                                                                   \n",
              "\u001b[0m\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;237;0;126;48;2;30;0;16m!\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpip\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34minstall\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mwandb\u001b[0m\u001b[48;2;39;40;34m                                                                                               \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m                                                                                                                 \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34mimport\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mwandb\u001b[0m\u001b[48;2;39;40;34m                                                                                                     \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mwandb\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mlogin\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                                    \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m                                                                                                                   \n",
              "\u001b[0m\n",
              "\n",
              "\n",
              "                                       \u001b[1;4mUsing PyTorch Lightning's \u001b[0m\u001b[1;4;36;40mWandbLogger\u001b[0m                                       \n",
              "\n",
              "PyTorch Lightning has a \u001b]8;id=251315;https://pytorch-lightning.readthedocs.io/en/latest/extensions/generated/pytorch_lightning.loggers.WandbLogger.html?highlight=wandblogger\u001b\\\u001b[1;4;36;40mWandbLogger\u001b[0m\u001b]8;;\u001b\\ class that can be used to seamlessly log metrics, model weights, media and     \n",
              "more. Just instantiate the WandbLogger and pass it to Lightning's \u001b[1;36;40mTrainer\u001b[0m.                                         \n",
              "\n",
              "\u001b[48;2;39;40;34m                                                                                                                   \n",
              "\u001b[0m\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mwandb_logger = WandbLogger()\u001b[0m\u001b[48;2;39;40;34m                                                                                     \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtrainer = Trainer(logger=wandb_logger)\u001b[0m\u001b[48;2;39;40;34m                                                                           \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m                                                                                                                   \n",
              "\u001b[0m\n",
              "                                                 \u001b[1mLogger arguments\u001b[0m                                                  \n",
              "\n",
              "Below are some of the most used parameters in WandbLogger, see the PyTorch Lightning \u001b]8;id=611078;https://pytorch-lightning.readthedocs.io/en/latest/extensions/generated/pytorch_lightning.loggers.WandbLogger.html?highlight=wandblogger\u001b\\\u001b[1;4;36;40mWandbLogger\u001b[0m\u001b]8;;\u001b\\\u001b]8;id=787292;https://pytorch-lightning.readthedocs.io/en/latest/extensions/generated/pytorch_lightning.loggers.WandbLogger.html?highlight=wandblogger\u001b\\\u001b[1;4;34m documentation\u001b[0m\u001b]8;;\u001b\\ for \n",
              "a full list and description                                                                                        \n",
              "\n",
              "                                                                                         \n",
              " \u001b[1m \u001b[0m\u001b[1mParameter\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDescription\u001b[0m\u001b[1m                                                              \u001b[0m\u001b[1m \u001b[0m \n",
              " ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \n",
              "  \u001b[1;36;40mproject\u001b[0m     Define what wandb Project to log to                                        \n",
              "  \u001b[1;36;40mname\u001b[0m        Give a name to your wandb run                                              \n",
              "  \u001b[1;36;40mlog_model\u001b[0m   Log all models if \u001b[1;36;40mlog_model=\"all\"\u001b[0m or at end of training if \u001b[1;36;40mlog_model=True\u001b[0m  \n",
              "  \u001b[1;36;40msave_dir\u001b[0m    Path where data is saved                                                   \n",
              "                                                                                         \n",
              "\n",
              "                                     \u001b[1mLog your LightningModule hyperparameters\u001b[0m                                      \n",
              "\n",
              "\u001b[48;2;39;40;34m                                                                                                                   \n",
              "\u001b[0m\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mclass\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;166;226;46;48;2;39;40;34mLitModule\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mLightningModule\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[48;2;39;40;34m                                                                                \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mdef\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;166;226;46;48;2;39;40;34m__init__\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mself\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m*\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34margs\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                                                    \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m*\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m*\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m*\u001b[0m\u001b[48;2;39;40;34m                                                                                                              \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mYou\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mwill\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mnow\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mgenerate\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34ma\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34muser\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mquestion\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34mand\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mcorresponding\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34manswer\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mbased\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mon\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mthe\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mabove\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdocument\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m                     \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mFirst\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mexplain\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mthe\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34muser\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mcontext\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34mand\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mwhat\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mproblems\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mthey\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mmight\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mbe\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtrying\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mto\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msolve\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m                                \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mSecond\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mgenerate\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34muser\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mquestion\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m                                                                                 \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mThird\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mprovide\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mthe\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34maccurate\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34mand\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mconcise\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34manswer\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34min\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mmarkdown\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mformat\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mto\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mthe\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34muser\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mquestion\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34musing\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mthe\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdocumentation\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mYou\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mll be evaluated on:\u001b[0m\u001b[48;2;39;40;34m                                                                                          \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m-\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mhow\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mrealistic\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34mis\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mthat\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mthis\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mquestion\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mwill\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mcome\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34mfrom\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34ma\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mreal\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34muser\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mone\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mday\u001b[0m\u001b[38;2;237;0;126;48;2;30;0;16m?\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m                                       \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m-\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34mis\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mthis\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mquestion\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mabout\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mW\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m&\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mB\u001b[0m\u001b[38;2;237;0;126;48;2;30;0;16m?\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m                                                                                   \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m-\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mcan\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mthe\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mquestion\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mbe\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34manswered\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34musing\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mthe\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mW\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m&\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mB\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdocument\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mfragment\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mabove\u001b[0m\u001b[38;2;237;0;126;48;2;30;0;16m?\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m                                           \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m-\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mhow\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34maccurate\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34mis\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mthe\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34manswer\u001b[0m\u001b[38;2;237;0;126;48;2;30;0;16m?\u001b[0m\u001b[48;2;39;40;34m                                                                                    \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mRemember\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mthat\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34musers\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mhave\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdifferent\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mstyles\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34mand\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mcan\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mbe\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mimprecise\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mYou\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mare\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mvery\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mgood\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mat\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mimpersonating\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mthem\u001b[0m\u001b[38;2;237;0;126;48;2;30;0;16m!\u001b[0m\u001b[48;2;39;40;34m         \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mUse\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mthe\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mfollowing\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mformat\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[48;2;39;40;34m                                                                                        \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mCONTEXT\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m                                                                                                        \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mQUESTION\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m                                                                                                       \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mANSWER\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m                                                                                                         \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mLet\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34ms start!\u001b[0m\u001b[48;2;39;40;34m                                                                                                     \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m                                                                                                                   \n",
              "\u001b[0m"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Here are some examples of real user questions, you will be judged by how well you match this distribution.         \n",
              "\n",
              "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
              "is there a W&amp;B integration for AutoKeras? Can you tell me why do sweeps often create the same runs and set same    \n",
              "hyper-parameters? I created the sweep with wandb offline. i have my log from training in a txt file. Can i import  \n",
              "that data to wandb so i can visualize the data? I have accuracy and loss logged every 50 steps on training data,   \n",
              "and every 5000 steps on validation data. How can I plot those two different accuracies and their losses?           \n",
              "\n",
              "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
              "In the next step, you will read a fragment of W&amp;B documentation. This will serve as inspiration for synthetic user \n",
              "question and the source of the answer. Here is the document fragment:                                              \n",
              "\n",
              "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
              ") for a free account                                                                                               \n",
              "\n",
              "b) Pip install the <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">wandb</span> library                                                                                   \n",
              "\n",
              "c) To login in your training script, you'll need to be signed in to you account at www.wandb.ai, then <span style=\"font-weight: bold\">you will find</span>\n",
              "<span style=\"font-weight: bold\">your API key on the</span> <a href=\"https://wandb.ai/authorize\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold; text-decoration: underline\">Authorize page</span></a><span style=\"font-weight: bold\">.</span>                                                                                \n",
              "\n",
              "If you are using Weights and Biases for the first time you might want to check out our <a href=\"../../quickstart.md\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold; text-decoration: underline\">quickstart</span></a>****              \n",
              "\n",
              "\n",
              "&lt;Tabs defaultValue=\"cli\" values={[ {label: 'Command Line', value: 'cli'}, {label: 'Notebook', value: 'notebook'},  \n",
              "]}&gt;                                                                                                                \n",
              "\n",
              "<span style=\"background-color: #272822\">                                                                                                                   \n",
              " </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">pip install wandb</span><span style=\"background-color: #272822\">                                                                                                 </span>\n",
              "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
              "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">wandb login</span><span style=\"background-color: #272822\">                                                                                                       </span>\n",
              "<span style=\"background-color: #272822\">                                                                                                                   \n",
              "</span>\n",
              "\n",
              "<span style=\"background-color: #272822\">                                                                                                                   \n",
              " </span><span style=\"color: #ed007e; text-decoration-color: #ed007e; background-color: #1e0010\">!</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">pip install wandb</span><span style=\"background-color: #272822\">                                                                                                </span>\n",
              "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
              "<span style=\"background-color: #272822\"> </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">import</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> wandb</span><span style=\"background-color: #272822\">                                                                                                      </span>\n",
              "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">wandb</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">login()</span><span style=\"background-color: #272822\">                                                                                                     </span>\n",
              "<span style=\"background-color: #272822\">                                                                                                                   \n",
              "</span>\n",
              "\n",
              "\n",
              "                                       <span style=\"font-weight: bold; text-decoration: underline\">Using PyTorch Lightning's </span><span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold; text-decoration: underline\">WandbLogger</span>                                       \n",
              "\n",
              "PyTorch Lightning has a <a href=\"https://pytorch-lightning.readthedocs.io/en/latest/extensions/generated/pytorch_lightning.loggers.WandbLogger.html?highlight=wandblogger\" target=\"_blank\"><span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold; text-decoration: underline\">WandbLogger</span></a> class that can be used to seamlessly log metrics, model weights, media and     \n",
              "more. Just instantiate the WandbLogger and pass it to Lightning's <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">Trainer</span>.                                         \n",
              "\n",
              "<span style=\"background-color: #272822\">                                                                                                                   \n",
              " </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">wandb_logger = WandbLogger()</span><span style=\"background-color: #272822\">                                                                                      </span>\n",
              "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">trainer = Trainer(logger=wandb_logger)</span><span style=\"background-color: #272822\">                                                                            </span>\n",
              "<span style=\"background-color: #272822\">                                                                                                                   \n",
              "</span>\n",
              "                                                 <span style=\"font-weight: bold\">Logger arguments</span>                                                  \n",
              "\n",
              "Below are some of the most used parameters in WandbLogger, see the PyTorch Lightning <a href=\"https://pytorch-lightning.readthedocs.io/en/latest/extensions/generated/pytorch_lightning.loggers.WandbLogger.html?highlight=wandblogger\" target=\"_blank\"><span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold; text-decoration: underline\">WandbLogger</span></a><a href=\"https://pytorch-lightning.readthedocs.io/en/latest/extensions/generated/pytorch_lightning.loggers.WandbLogger.html?highlight=wandblogger\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold; text-decoration: underline\"> documentation</span></a> for \n",
              "a full list and description                                                                                        \n",
              "\n",
              "                                                                                         \n",
              " <span style=\"font-weight: bold\"> Parameter </span> <span style=\"font-weight: bold\"> Description                                                               </span> \n",
              " ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \n",
              "  <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">project</span>     Define what wandb Project to log to                                        \n",
              "  <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">name</span>        Give a name to your wandb run                                              \n",
              "  <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">log_model</span>   Log all models if <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">log_model=\"all\"</span> or at end of training if <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">log_model=True</span>  \n",
              "  <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">save_dir</span>    Path where data is saved                                                   \n",
              "                                                                                         \n",
              "\n",
              "                                     <span style=\"font-weight: bold\">Log your LightningModule hyperparameters</span>                                      \n",
              "\n",
              "<span style=\"background-color: #272822\">                                                                                                                   \n",
              " </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">class</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #a6e22e; text-decoration-color: #a6e22e; background-color: #272822\">LitModule</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">(LightningModule):</span><span style=\"background-color: #272822\">                                                                                 </span>\n",
              "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">def</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #a6e22e; text-decoration-color: #a6e22e; background-color: #272822\">__init__</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">(self, </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">*</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">args,</span><span style=\"background-color: #272822\">                                                                                     </span>\n",
              "<span style=\"background-color: #272822\"> </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">***</span><span style=\"background-color: #272822\">                                                                                                               </span>\n",
              "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">You will now generate a user question </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">and</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> corresponding answer based on the above document</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"background-color: #272822\">                      </span>\n",
              "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">First, explain the user context </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">and</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> what problems they might be trying to solve</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"background-color: #272822\">                                 </span>\n",
              "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">Second, generate user question</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"background-color: #272822\">                                                                                  </span>\n",
              "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">Third, provide the accurate </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">and</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> concise answer </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">in</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> markdown format to the user question using the documentation</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"background-color: #272822\">  </span>\n",
              "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">You</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">'ll be evaluated on:</span><span style=\"background-color: #272822\">                                                                                           </span>\n",
              "<span style=\"background-color: #272822\"> </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">-</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> how realistic </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">is</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> that this question will come </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">from</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> a real user one day</span><span style=\"color: #ed007e; text-decoration-color: #ed007e; background-color: #1e0010\">?</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"background-color: #272822\">                                        </span>\n",
              "<span style=\"background-color: #272822\"> </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">-</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">is</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> this question about W</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">&amp;</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">B</span><span style=\"color: #ed007e; text-decoration-color: #ed007e; background-color: #1e0010\">?</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"background-color: #272822\">                                                                                    </span>\n",
              "<span style=\"background-color: #272822\"> </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">-</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> can the question be answered using the W</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">&amp;</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">B document fragment above</span><span style=\"color: #ed007e; text-decoration-color: #ed007e; background-color: #1e0010\">?</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"background-color: #272822\">                                            </span>\n",
              "<span style=\"background-color: #272822\"> </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">-</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> how accurate </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">is</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> the answer</span><span style=\"color: #ed007e; text-decoration-color: #ed007e; background-color: #1e0010\">?</span><span style=\"background-color: #272822\">                                                                                     </span>\n",
              "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">Remember that users have different styles </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">and</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> can be imprecise</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> You are very good at impersonating them</span><span style=\"color: #ed007e; text-decoration-color: #ed007e; background-color: #1e0010\">!</span><span style=\"background-color: #272822\">          </span>\n",
              "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">Use the following format:</span><span style=\"background-color: #272822\">                                                                                         </span>\n",
              "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">CONTEXT: </span><span style=\"background-color: #272822\">                                                                                                         </span>\n",
              "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">QUESTION: </span><span style=\"background-color: #272822\">                                                                                                        </span>\n",
              "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">ANSWER: </span><span style=\"background-color: #272822\">                                                                                                          </span>\n",
              "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">Let</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">'s start!</span><span style=\"background-color: #272822\">                                                                                                      </span>\n",
              "<span style=\"background-color: #272822\">                                                                                                                   \n",
              "</span></pre>\n"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_questions(documents, n_questions=3, n_generations=5):\n",
        "    questions = []\n",
        "    for _, document in documents:\n",
        "        chunk = extract_random_chunk(document)\n",
        "        user_prompt = generate_context_prompt(chunk, n_questions)\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_prompt},\n",
        "        ]\n",
        "        response = completion_with_backoff(\n",
        "            model=MODEL_NAME,\n",
        "            messages=messages,\n",
        "            n = n_generations,\n",
        "            )\n",
        "        questions.extend([response.choices[i].message.content for i in range(n_generations)])\n",
        "    return questions"
      ],
      "metadata": {
        "id": "adoNoyVYd1SL"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to parse model generation and extract CONTEXT, QUESTION and ANSWER\n",
        "def parse_generation(generation):\n",
        "    lines = generation.split(\"\\n\")\n",
        "    context = []\n",
        "    question = []\n",
        "    answer = []\n",
        "    flag = None\n",
        "\n",
        "    for line in lines:\n",
        "        if \"CONTEXT:\" in line:\n",
        "            flag = \"context\"\n",
        "            line = line.replace(\"CONTEXT:\", \"\").strip()\n",
        "        elif \"QUESTION:\" in line:\n",
        "            flag = \"question\"\n",
        "            line = line.replace(\"QUESTION:\", \"\").strip()\n",
        "        elif \"ANSWER:\" in line:\n",
        "            flag = \"answer\"\n",
        "            line = line.replace(\"ANSWER:\", \"\").strip()\n",
        "\n",
        "        if flag == \"context\":\n",
        "            context.append(line)\n",
        "        elif flag == \"question\":\n",
        "            question.append(line)\n",
        "        elif flag == \"answer\":\n",
        "            answer.append(line)\n",
        "\n",
        "    context = \"\\n\".join(context)\n",
        "    question = \"\\n\".join(question)\n",
        "    answer = \"\\n\".join(answer)\n",
        "    return context, question, answer"
      ],
      "metadata": {
        "id": "EGhU7NFBeRSE"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generations = generate_questions([documents[0]], n_questions=3, n_generations=5)\n",
        "parse_generation(generations[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7a5ECRceU_c",
        "outputId": "f7903919-a4bb-4123-aacd-affe79f09232"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('The user is working on a deep learning project and is using the PyTorch Lightning library along with Weights & Biases for experiment tracking and visualization. They have implemented a custom PyTorch Lightning module and want guidance on how to log metrics during the training and validation steps.\\n',\n",
              " 'How can I log the training loss and accuracy metrics during my PyTorch Lightning training step using Weights & Biases?\\n',\n",
              " \"To log the training loss and accuracy metrics during your PyTorch Lightning training step using Weights & Biases, you can use the `self.log()` method. Inside the `training_step()` method of your LightningModule, you can call `self.log('train_loss', loss)` to log the training loss and `self.log('train_accuracy', acc)` to log the training accuracy. These metrics will be automatically logged by Weights & Biases and visualized in your W&B dashboard.\")"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parsed_generations = []\n",
        "generations = generate_questions(documents, n_questions=3, n_generations=5)\n",
        "for generation in generations:\n",
        "    context, question, answer = parse_generation(generation)\n",
        "    parsed_generations.append({\"context\": context, \"question\": question, \"answer\": answer})\n",
        "\n",
        "# let's convert parsed_generations to a pandas dataframe and save it locally\n",
        "df = pd.DataFrame(parsed_generations)\n",
        "df.to_csv('generated_examples.csv', index=False)\n",
        "\n",
        "# log df as a table to W&B for interactive exploration\n",
        "wandb.log({\"generated_examples\": wandb.Table(dataframe=df)})\n",
        "\n",
        "# log csv file as an artifact to W&B for later use\n",
        "artifact = wandb.Artifact(\"generated_examples\", type=\"dataset\")\n",
        "artifact.add_file(\"generated_examples.csv\")\n",
        "wandb.log_artifact(artifact)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLB0aBCVeYpF",
        "outputId": "85a38be0-4815-41d1-b38a-1093c2aa6aba"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Artifact generated_examples>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248,
          "referenced_widgets": [
            "e5a003f9e5304cefadea978c88ba685e",
            "d6ed0b27ee5c49f0bb55240ed3e8106e",
            "4d06cc021e7a4ce0a3b1febc97aa8169",
            "783e7bca7c1c4993a36b60f782c9e6dd",
            "758ee1fc0b9a4da7bf13b51f4cbdb1d8",
            "348f2d1b8ac749c9ab6503ad2c99ee57",
            "77e4147dda8d42d7b0147c2cd34dd78e",
            "fa5bcd7457ea4e669fc6add27c66ee10"
          ]
        },
        "id": "EJ5lMxaDei8C",
        "outputId": "01f91b56-a716-4a6f-9ecc-d6e57ab39bc2"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.910 MB of 0.910 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e5a003f9e5304cefadea978c88ba685e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>usage/completion_tokens</td><td>▁▁▂▆█▇▇█▆▇▆▄▆▅▆</td></tr><tr><td>usage/elapsed_time</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>usage/prompt_tokens</td><td>▁▂▄▆▇▆▆▆▅▆▅██▆▆</td></tr><tr><td>usage/total_tokens</td><td>▁▂▃▆█▇▇▇▆▇▆▇█▆▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>usage/completion_tokens</td><td>1138</td></tr><tr><td>usage/elapsed_time</td><td>0.0</td></tr><tr><td>usage/prompt_tokens</td><td>1064</td></tr><tr><td>usage/total_tokens</td><td>2202</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">magic-brook-2</strong> at: <a href='https://wandb.ai/ayodejiyou/llmapps/runs/pybou6br' target=\"_blank\">https://wandb.ai/ayodejiyou/llmapps/runs/pybou6br</a><br/>Synced 5 W&B file(s), 16 media file(s), 17 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240116_175611-pybou6br/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retrieval"
      ],
      "metadata": {
        "id": "zRQnH8Aheu18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -Uqqq rich openai==0.27.2 tiktoken wandb langchain unstructured tabulate pdf2image chromadb"
      ],
      "metadata": {
        "id": "t8qXCkYeet4W"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, random\n",
        "from pathlib import Path\n",
        "import tiktoken\n",
        "from getpass import getpass\n",
        "from rich.markdown import Markdown"
      ],
      "metadata": {
        "id": "1OCbDJF4gI8v"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we need a single line of code to start tracing langchain with W&B\n",
        "os.environ[\"LANGCHAIN_WANDB_TRACING\"] = \"true\"\n",
        "\n",
        "# wandb documentation to configure wandb using env variables\n",
        "# https://docs.wandb.ai/guides/track/advanced/environment-variables\n",
        "# here we are configuring the wandb project name\n",
        "os.environ[\"WANDB_PROJECT\"] = \"llmapps\""
      ],
      "metadata": {
        "id": "jaAV2PdLgVlH"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parsing Documents"
      ],
      "metadata": {
        "id": "AM3KW9-2gjiM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import DirectoryLoader\n",
        "\n",
        "def find_md_files(directory):\n",
        "    \"Find all markdown files in a directory and return a LangChain Document\"\n",
        "    dl = DirectoryLoader(directory, \"**/*.md\")\n",
        "    return dl.load()\n",
        "\n",
        "documents = find_md_files('edu/llm-apps-course/docs_sample/')\n",
        "len(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4BvV9WTgdGZ",
        "outputId": "66ca8177-be7d-4292-ddb5-d817e098bf68"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We will need to count tokens in the documents, and for that we need the tokenizer\n",
        "tokenizer = tiktoken.encoding_for_model(MODEL_NAME)"
      ],
      "metadata": {
        "id": "dGb7GYrCgsSg"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to count the number of tokens in each document\n",
        "def count_tokens(documents):\n",
        "    token_counts = [len(tokenizer.encode(document.page_content)) for document in documents]\n",
        "    return token_counts\n",
        "\n",
        "count_tokens(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNbalee1g0QK",
        "outputId": "dd66b8a0-0f55-4d44-fa65-f7af7d4b4693"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2116, 1901, 626, 1023, 288, 650, 2209, 1499, 954, 2062, 342]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import MarkdownTextSplitter\n",
        "\n",
        "md_text_splitter = MarkdownTextSplitter(chunk_size=1000)\n",
        "document_sections = md_text_splitter.split_documents(documents)\n",
        "len(document_sections), max(count_tokens(document_sections))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRZ0pmmdg4H5",
        "outputId": "42995d26-2535-4b00-bb80-af20b818f25d"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(88, 382)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Markdown(document_sections[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "Hmv7vicFg8xH",
        "outputId": "39c507cc-ad51-4996-dbc1-0ee265b8d4c8"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "import Tabs from '@theme/Tabs'; import TabItem from '@theme/TabItem';                                              \n",
              "\n",
              "PyTorch Lightning                                                                                                  \n",
              "\n",
              "PyTorch Lightning provides a lightweight wrapper for organizing your PyTorch code and easily adding advanced       \n",
              "features such as distributed training and 16-bit precision. W&B provides a lightweight wrapper for logging your ML \n",
              "experiments. But you don't need to combine the two yourself: Weights & Biases is incorporated directly into the    \n",
              "PyTorch Lightning library via the WandbLogger.                                                                     \n",
              "\n",
              "⚡ Get going lightning-fast with just two lines.                                                                   \n",
              "\n",
              "\u001b[48;2;39;40;34m                                                                                                                   \n",
              "\u001b[0m\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34mfrom\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpytorch_lightning\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mloggers\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34mimport\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mWandbLogger\u001b[0m\u001b[48;2;39;40;34m                                                                \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34mfrom\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpytorch_lightning\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34mimport\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mTrainer\u001b[0m\u001b[48;2;39;40;34m                                                                            \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m                                                                                                                 \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mwandb_logger\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mWandbLogger\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                     \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtrainer\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mTrainer\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mlogger\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mwandb_logger\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                           \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m                                                                                                                   \n",
              "\u001b[0m"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">import Tabs from '@theme/Tabs'; import TabItem from '@theme/TabItem';                                              \n",
              "\n",
              "PyTorch Lightning                                                                                                  \n",
              "\n",
              "PyTorch Lightning provides a lightweight wrapper for organizing your PyTorch code and easily adding advanced       \n",
              "features such as distributed training and 16-bit precision. W&amp;B provides a lightweight wrapper for logging your ML \n",
              "experiments. But you don't need to combine the two yourself: Weights &amp; Biases is incorporated directly into the    \n",
              "PyTorch Lightning library via the WandbLogger.                                                                     \n",
              "\n",
              "⚡ Get going lightning-fast with just two lines.                                                                   \n",
              "\n",
              "<span style=\"background-color: #272822\">                                                                                                                   \n",
              " </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">from</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> pytorch_lightning.loggers </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">import</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> WandbLogger</span><span style=\"background-color: #272822\">                                                                 </span>\n",
              "<span style=\"background-color: #272822\"> </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">from</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> pytorch_lightning </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">import</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> Trainer</span><span style=\"background-color: #272822\">                                                                             </span>\n",
              "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
              "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">wandb_logger </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> WandbLogger()</span><span style=\"background-color: #272822\">                                                                                      </span>\n",
              "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">trainer </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> Trainer(logger</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">wandb_logger)</span><span style=\"background-color: #272822\">                                                                            </span>\n",
              "<span style=\"background-color: #272822\">                                                                                                                   \n",
              "</span></pre>\n"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embeddings"
      ],
      "metadata": {
        "id": "uYAIXecBhOus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cZWdphOjkGQ",
        "outputId": "249efaae-3e57-4b6b-d747-736b401c136d"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "edu\t      generated_examples.csv  sample_data\t   wandb\n",
            "examples.txt  prompt_template.txt     system_template.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb -q"
      ],
      "metadata": {
        "id": "W8lDl18hhSM3"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "# We will use the OpenAIEmbeddings to embed the text, and Chroma to store the vectors\n",
        "embeddings = OpenAIEmbeddings()\n",
        "db = Chroma.from_documents(document_sections, embeddings)"
      ],
      "metadata": {
        "id": "-KzI2kXjhCgd"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = db.as_retriever(search_kwargs=dict(k=3))"
      ],
      "metadata": {
        "id": "gmFfi4Ush9v7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"How can I share my W&B report with my team members in a public W&B project?\"\n",
        "docs = retriever.get_relevant_documents(query)"
      ],
      "metadata": {
        "id": "LLv1v9GjmFuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see the results\n",
        "for doc in docs:\n",
        "    print(doc.metadata[\"source\"])"
      ],
      "metadata": {
        "id": "kz5OePYsmFo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt_template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
        "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "Helpful Answer:\"\"\"\n",
        "PROMPT = PromptTemplate(\n",
        "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
        ")\n",
        "\n",
        "context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
        "prompt = PROMPT.format(context=context, question=query)"
      ],
      "metadata": {
        "id": "j7VkhGq-mFh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI()\n",
        "response = llm.predict(prompt)\n",
        "Markdown(response)"
      ],
      "metadata": {
        "id": "gLtKW1qjmNVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", retriever=retriever)\n",
        "result = qa.run(query)\n",
        "\n",
        "Markdown(result)"
      ],
      "metadata": {
        "id": "9fVVYifcmSFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "id": "O3Eznb3FmPoQ"
      },
      "execution_count": 92,
      "outputs": []
    }
  ]
}